{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexv710/debias_cv_data/blob/main/DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pWPPfS8TtfMG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "50jslTNru8ol"
   },
   "outputs": [],
   "source": [
    "# temp_data = pd.io.stata.read_stata(\"data_candidates_sample_tab6.dta\")\n",
    "# temp_data.to_csv('data_candidates_sample_tab6.csv')\n",
    "\n",
    "# temp_data = pd.io.stata.read_stata(\"data_candidates_sample_tab7_tabA9.dta\")\n",
    "# temp_data.to_csv('data_candidates_sample_tab7_tabA9.csv')\n",
    "\n",
    "# temp_data = pd.io.stata.read_stata(\"data_recruiters.dta\")\n",
    "# temp_data.to_csv('data_recruiters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SbWNo8iowTg8"
   },
   "outputs": [],
   "source": [
    "# read the mainsample.dta file for further processing \n",
    "data = pd.io.stata.read_stata(\"data_candidates_mainsample.dta\")\n",
    "data.to_csv('data_candidates_mainsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1aMoiVvsmdo7"
   },
   "outputs": [],
   "source": [
    "# Import the mainsample via StataReader to use variable_labels (old version of the read_stata)\n",
    "data_stata = pd.io.stata.StataReader(\"data_candidates_mainsample.dta\")\n",
    "data_labels = data_stata.variable_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xikrwWpRoY6n"
   },
   "outputs": [],
   "source": [
    "# Write the Labels into a csv\n",
    "#import csv\n",
    "\n",
    "# with open('dataLabels.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "#    w = csv.DictWriter(f, data_labels.keys())\n",
    "#    w.writeheader()\n",
    "#    w.writerow(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlN5XSOopE_t",
    "outputId": "3e4f8c99-0ce5-4df6-bd41-bd36da5241d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVA:       Treatment: anonymous resume\n",
      "REFUSAL:       Recruiter refused the experiment\n",
      "ENTRETIEN:       Interviewed\n",
      "RECRUTE:       Hired\n",
      "PREN_MUSULMAN:       Muslim souding name\n",
      "ZUS_CUCS:       Deprived neighborhood\n",
      "ZouI:       Minority (immigrant or child of immigrant or residing in deprived neighborhood)\n",
      "ZetI:       Residing in deprived neighborhood and with foreign bachkground (child of or immi\n",
      "FEMME:       Female candidate\n",
      "a50p:       Candidate over 50 years old\n",
      "a3049:       Candidate between 30 and 49 years old\n",
      "a26m:       Candidate below 26 years old\n",
      "dip_aucun:       No diploma\n",
      "dip_bepcap:       Professional degree\n",
      "dip_bac:       High school diploma\n",
      "dip_bac2p:       Upper education degree\n",
      "dip_bac2:       L2 (diploma 2 years after high school)\n",
      "dip_bac3p:       At least L3 (diploma 3 years after high school)\n",
      "duree_expro_offre:       Work experience for the job advertised (in years)\n",
      "recherche_LD:       Candidate has been looking for a job for at least one year\n",
      "recherche_TLD:       Candidate has been looking for a job for at least two years\n",
      "SALREV_SMIC_2:       Reservation wage of the candidate is the minimum wage\n",
      "permis:       Candidate has a driving license (Resume)\n",
      "etudes_etranger:       Candidate has studied abroad (Resume coding)\n",
      "travail_etranger:       Candidate has worked abroad (Resume coding)\n",
      "langue_anglais:       Candidate speaks English (Resume)\n",
      "langue_arabe:       Candidate speaks Arabic (Resume)\n",
      "langue_autres:       Candidate speaks another foreign language (Resume)\n",
      "codage_cv:       Resume has been coded\n",
      "CV_note_7p:       High overall rating (Resume coding)\n",
      "CV_hesit:       Uncertain rating (Resume coding)\n",
      "CV_inactivite:       Interrupted work history (Resume coding)\n",
      "CV_qualif:       Adequate skills (Resume coding)\n",
      "CV_experience_3p:       Adequate work experience (Resume coding)\n",
      "CV_note_2:       Low grade (Resume coding)\n",
      "CV_note_3:       Medium grade (Resume coding)\n",
      "CV_note_4:       High grade (Resume coding)\n",
      "CV_note_5:       Very high grade (Resume coding)\n",
      "CV_hesit_:       Uncertain rating scale 1-4 (Resume coding)\n",
      "CV_qualif_sup:       Candidate overqualified for the vacancy (Resume coding)\n",
      "CV_qualif_inf:       Candidate underqualified for the vacancy (Resume coding)\n",
      "CV_experience_:       Adequate work experience scale 1-4 (Resume coding)\n",
      "CV_attrayant_:       Attractive resume (Resume coding)\n",
      "CV_formation_:       Adequate skills (Resume coding)\n",
      "effent_200plus:       Firm size greater than 200 employees (vacancy)\n",
      "service_nm:       Non-market services (vacancy)\n",
      "service_m:       Market services (vacancy)\n",
      "industrie:       Manufacturing (vacancy)\n",
      "construction:       Construction (vacancy)\n",
      "cadre:       Upper occupation (vacancy)\n",
      "profint:       Intermediary occupation (vacancy)\n",
      "eoq:       Skilled white or blue collar (vacancy)\n",
      "CDI:       Indefinite duration contract (vacancy)\n",
      "CNT_sup6m:       Temporary contract for more than 6 months (vacancy)\n",
      "poste_unique:       Vacnacy with only one position\n",
      "ALE_1:       Dummy for local job center\n",
      "ALE_2:       Dummy for local job center\n",
      "ALE_3:       Dummy for local job center\n",
      "ALE_4:       Dummy for local job center\n",
      "ALE_5:       Dummy for local job center\n",
      "ALE_6:       Dummy for local job center\n",
      "ALE_7:       Dummy for local job center\n",
      "ALE_8:       Dummy for local job center\n",
      "ALE_9:       Dummy for local job center\n",
      "ALE_10:       Dummy for local job center\n",
      "ALE_11:       Dummy for local job center\n",
      "ALE_12:       Dummy for local job center\n",
      "ALE_13:       Dummy for local job center\n",
      "ALE_14:       Dummy for local job center\n",
      "ALE_15:       Dummy for local job center\n"
     ]
    }
   ],
   "source": [
    "# Remove all columns in the dataset for which no labels exist\n",
    "# Those are mostly columns needed for p-tests and some matrix calculations in\n",
    "# Stata. The outputted labels are those that are kept in the data\n",
    "\n",
    "data = data.drop(columns=['CVAxORIGINE_IM_12', 'CVAxZUS_CUCS', 'CVAxZetI', 'C', 'CVA0', 'p_offre1', 'control_manquant', 'ZouI_pred', 'ZouI0', 'ALE_16'])\n",
    "\n",
    "# Remove sampling weights (within and out of the experiment)\n",
    "\n",
    "data = data.drop(columns='POIDS_SEL')\n",
    "\n",
    "# Remove all the centered features\n",
    "\n",
    "data = data.drop(columns=['FEMME_c', 'a30m_c', 'a3049_c', 'a50p_c', 'dip_aucun_c', 'dip_bepcap_c', 'dip_bac_c', 'dip_bac2p_c', 'recherche_LD_c', 'recherche_TLD_c'])\n",
    "\n",
    "# Remove all features that are not directly derivable from the CVs\n",
    "\n",
    "data = data.drop(columns=['ORIGINE_IM_1', 'ORIGINE_IM_2', 'ORIGINE_IM_12', 'ID_OFFRE', 'ID_CANDIDAT', ])\n",
    "\n",
    "for key, value in data_labels.items():\n",
    "  for col in data.columns:\n",
    "    if key==col:\n",
    "      if len(value)==0 or value.startswith('ID_OFFRE=='):\n",
    "        data = data.drop(columns=col)\n",
    "      else:\n",
    "        # Print all the columns that are included in the dataset\n",
    "        print(key + ':      ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F-jU5Dh8vCNL"
   },
   "outputs": [],
   "source": [
    "X_ano = pd.DataFrame()\n",
    "X_unano = pd.DataFrame()\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "  if row['CVA'] == 1: \n",
    "    X_ano = X_ano.append(row)\n",
    "  else:\n",
    "    X_unano = X_unano.append(row)\n",
    "\n",
    "# Assign the interviewed column to our target vector\n",
    "y_ano = X_ano['ENTRETIEN']\n",
    "y_unano = X_unano['ENTRETIEN']\n",
    "\n",
    "# Drop the Interviewed/hired & anonymized columns (hired is much dependend on the number of jobs available\n",
    "# and will currently not be considered as target label)\n",
    "X_ano = data.drop(columns=['ENTRETIEN', 'RECRUTE', 'CVA'])\n",
    "X_unano = X_unano.drop(columns=['ENTRETIEN', 'RECRUTE', 'CVA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VtZQgElRw39P"
   },
   "outputs": [],
   "source": [
    "X_unano.to_csv('X_unano.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uEVp3Kri1LYd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rgKAkwAZdp3I"
   },
   "outputs": [],
   "source": [
    "# Train, Test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_unano, y_unano, test_size=0.33, random_state=42)\n",
    "\n",
    "input_shape = X_train[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALE_1', 'ALE_10', 'ALE_11', 'ALE_12', 'ALE_13', 'ALE_14', 'ALE_15',\n",
       "       'ALE_2', 'ALE_3', 'ALE_4', 'ALE_5', 'ALE_6', 'ALE_7', 'ALE_8', 'ALE_9',\n",
       "       'CDI', 'CNT_sup6m', 'CV_attrayant_', 'CV_experience_',\n",
       "       'CV_experience_3p', 'CV_formation_', 'CV_hesit', 'CV_hesit_',\n",
       "       'CV_inactivite', 'CV_note_2', 'CV_note_3', 'CV_note_4', 'CV_note_5',\n",
       "       'CV_note_7p', 'CV_qualif', 'CV_qualif_inf', 'CV_qualif_sup', 'FEMME',\n",
       "       'PREN_MUSULMAN', 'REFUSAL', 'SALREV_SMIC_2', 'ZUS_CUCS', 'ZetI', 'ZouI',\n",
       "       'a26m', 'a3049', 'a50p', 'cadre', 'codage_cv', 'construction',\n",
       "       'dip_aucun', 'dip_bac', 'dip_bac2', 'dip_bac2p', 'dip_bac3p',\n",
       "       'dip_bepcap', 'duree_expro_offre', 'effent_200plus', 'eoq',\n",
       "       'etudes_etranger', 'industrie', 'langue_anglais', 'langue_arabe',\n",
       "       'langue_autres', 'permis', 'poste_unique', 'profint', 'recherche_LD',\n",
       "       'recherche_TLD', 'service_m', 'service_nm', 'travail_etranger'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAgaYgbPd4RR",
    "outputId": "20cfe020-7e13-4372-974f-4d67a200e08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simpleNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                2176      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "\n",
    "name=\"simpleNet\"\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(32, input_dim=67, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  \n",
    "    \n",
    "    ],name=name\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "t-xCiBM1kRYy"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PdwJ4smkRgT",
    "outputId": "64dd16f1-b5a0-450e-84f2-b0b316957b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 2/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 3/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 4/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 5/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 6/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 7/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 8/150\n",
      "58/58 [==============================] - 0s 568us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 9/150\n",
      "58/58 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 10/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 11/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 12/150\n",
      "58/58 [==============================] - 0s 638us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 13/150\n",
      "58/58 [==============================] - 0s 638us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 14/150\n",
      "58/58 [==============================] - 0s 597us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 15/150\n",
      "58/58 [==============================] - 0s 494us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 16/150\n",
      "58/58 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 17/150\n",
      "58/58 [==============================] - 0s 649us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 18/150\n",
      "58/58 [==============================] - 0s 673us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 19/150\n",
      "58/58 [==============================] - 0s 498us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 20/150\n",
      "58/58 [==============================] - 0s 638us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 21/150\n",
      "58/58 [==============================] - 0s 649us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 22/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 23/150\n",
      "58/58 [==============================] - 0s 544us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 24/150\n",
      "58/58 [==============================] - 0s 719us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 25/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 26/150\n",
      "58/58 [==============================] - 0s 583us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 27/150\n",
      "58/58 [==============================] - 0s 629us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 28/150\n",
      "58/58 [==============================] - 0s 678us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 29/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 30/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 31/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 32/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 33/150\n",
      "58/58 [==============================] - 0s 638us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 34/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 35/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 36/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 37/150\n",
      "58/58 [==============================] - 0s 540us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 38/150\n",
      "58/58 [==============================] - 0s 558us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 39/150\n",
      "58/58 [==============================] - 0s 541us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 40/150\n",
      "58/58 [==============================] - 0s 524us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 41/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 42/150\n",
      "58/58 [==============================] - 0s 523us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 43/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 44/150\n",
      "58/58 [==============================] - 0s 540us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 45/150\n",
      "58/58 [==============================] - 0s 541us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 46/150\n",
      "58/58 [==============================] - 0s 504us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 47/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 48/150\n",
      "58/58 [==============================] - 0s 573us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 49/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 50/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 51/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 52/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 53/150\n",
      "58/58 [==============================] - 0s 576us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 54/150\n",
      "58/58 [==============================] - 0s 660us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 55/150\n",
      "58/58 [==============================] - 0s 551us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 56/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 57/150\n",
      "58/58 [==============================] - 0s 576us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 58/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 59/150\n",
      "58/58 [==============================] - 0s 576us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 60/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 61/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 62/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 63/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 64/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 65/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 66/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 67/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 68/150\n",
      "58/58 [==============================] - 0s 578us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 69/150\n",
      "58/58 [==============================] - 0s 682us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 70/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 71/150\n",
      "58/58 [==============================] - 0s 637us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 72/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 73/150\n",
      "58/58 [==============================] - 0s 638us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 74/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 619us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 76/150\n",
      "58/58 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 77/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 78/150\n",
      "58/58 [==============================] - 0s 541us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 79/150\n",
      "58/58 [==============================] - 0s 577us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 80/150\n",
      "58/58 [==============================] - 0s 523us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 81/150\n",
      "58/58 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 82/150\n",
      "58/58 [==============================] - 0s 602us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 83/150\n",
      "58/58 [==============================] - 0s 588us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 84/150\n",
      "58/58 [==============================] - 0s 608us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 85/150\n",
      "58/58 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 86/150\n",
      "58/58 [==============================] - 0s 551us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 87/150\n",
      "58/58 [==============================] - 0s 580us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 88/150\n",
      "58/58 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 89/150\n",
      "58/58 [==============================] - 0s 558us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 90/150\n",
      "58/58 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 91/150\n",
      "58/58 [==============================] - 0s 534us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 92/150\n",
      "58/58 [==============================] - 0s 535us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 93/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 94/150\n",
      "58/58 [==============================] - 0s 581us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 95/150\n",
      "58/58 [==============================] - 0s 518us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 96/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 97/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 98/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 99/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 100/150\n",
      "58/58 [==============================] - 0s 550us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 101/150\n",
      "58/58 [==============================] - 0s 540us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 102/150\n",
      "58/58 [==============================] - 0s 553us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 103/150\n",
      "58/58 [==============================] - 0s 549us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 104/150\n",
      "58/58 [==============================] - 0s 541us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 105/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 106/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 107/150\n",
      "58/58 [==============================] - 0s 556us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 108/150\n",
      "58/58 [==============================] - 0s 606us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 109/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 110/150\n",
      "58/58 [==============================] - 0s 604us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 111/150\n",
      "58/58 [==============================] - 0s 583us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 112/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 113/150\n",
      "58/58 [==============================] - 0s 571us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 114/150\n",
      "58/58 [==============================] - 0s 532us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 115/150\n",
      "58/58 [==============================] - 0s 521us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 116/150\n",
      "58/58 [==============================] - 0s 553us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 117/150\n",
      "58/58 [==============================] - 0s 578us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 118/150\n",
      "58/58 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 119/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 120/150\n",
      "58/58 [==============================] - 0s 568us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 121/150\n",
      "58/58 [==============================] - 0s 564us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 122/150\n",
      "58/58 [==============================] - 0s 558us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 123/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 124/150\n",
      "58/58 [==============================] - 0s 554us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 125/150\n",
      "58/58 [==============================] - 0s 576us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 126/150\n",
      "58/58 [==============================] - 0s 530us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 127/150\n",
      "58/58 [==============================] - 0s 582us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 128/150\n",
      "58/58 [==============================] - 0s 573us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 129/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 130/150\n",
      "58/58 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 131/150\n",
      "58/58 [==============================] - 0s 566us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 132/150\n",
      "58/58 [==============================] - 0s 529us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 133/150\n",
      "58/58 [==============================] - 0s 553us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 134/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 135/150\n",
      "58/58 [==============================] - 0s 523us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 136/150\n",
      "58/58 [==============================] - 0s 538us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 137/150\n",
      "58/58 [==============================] - 0s 535us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 138/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 139/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 140/150\n",
      "58/58 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 141/150\n",
      "58/58 [==============================] - 0s 547us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 142/150\n",
      "58/58 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 143/150\n",
      "58/58 [==============================] - 0s 540us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 144/150\n",
      "58/58 [==============================] - 0s 535us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 145/150\n",
      "58/58 [==============================] - 0s 542us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 146/150\n",
      "58/58 [==============================] - 0s 552us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 147/150\n",
      "58/58 [==============================] - 0s 577us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 148/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n",
      "Epoch 150/150\n",
      "58/58 [==============================] - 0s 586us/step - loss: nan - accuracy: 0.8858 - mse: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223e71bdd30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ay_AE3snkRlZ",
    "outputId": "ae83d75f-6b25-4a26-8499-649be6a4ad00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.8982 - mse: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-5fdf01bc34d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "za_UZ-amhGku",
    "outputId": "01b5992f-b0a8-41a6-c5da-3638bb00e574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 4/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: nan - accuracy: 0.9062\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 7/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: nan - accuracy: 0.9141\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 9/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: nan - accuracy: 0.8672Restoring model weights from the end of the best epoch.\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.8865 - val_loss: nan - val_accuracy: 0.8793\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(epsilon=1e-07, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "log_dir= os.path.join('logs','fit_'+name,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'')\n",
    "\n",
    "#Learning Rate Annealer\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lrr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                       factor=.01,\n",
    "                       patience=3,\n",
    "                       min_lr=1e-7,\n",
    "                       verbose=1)\n",
    "#Early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True)\n",
    "\n",
    "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history=model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,callbacks=[es, lrr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnWoOGhNhRa0"
   },
   "outputs": [],
   "source": [
    "input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB2psoLqiDYA"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLrOIHZPnxsl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMx4wby1WPbtAPN3QDLbQDM",
   "include_colab_link": true,
   "name": "DataPreprocessing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
